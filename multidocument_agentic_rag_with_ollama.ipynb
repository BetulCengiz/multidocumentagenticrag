{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import faiss\n",
    "import nest_asyncio\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, SummaryIndex\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.tools import FunctionTool, QueryEngineTool\n",
    "from llama_index.core.vector_stores import MetadataFilters, FilterCondition\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "#from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama-index\n",
    "llama-index-llms-huggingface\n",
    "llama-index-embeddings-fastembed\n",
    "fastembed\n",
    "Unstructured[md]\n",
    "chromadb\n",
    "llama-index-vector-stores-chroma\n",
    "llama-index-llms-groq\n",
    "einops\n",
    "accelerate\n",
    "sentence-transformers\n",
    "llama-index-llms-mistralai\n",
    "llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply() #birden fazla olay döngüsünü aynı anda çalıştırabilmek için "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOllama\u001b[0m\n",
      "Params: {'model': 'llama3.1', 'format': None, 'options': {'mirostat': None, 'mirostat_eta': None, 'mirostat_tau': None, 'num_ctx': None, 'num_gpu': None, 'num_thread': None, 'num_predict': None, 'repeat_last_n': None, 'repeat_penalty': None, 'temperature': None, 'stop': None, 'tfs_z': None, 'top_k': None, 'top_p': None}, 'system': None, 'template': None, 'keep_alive': None, 'raw': None}\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from llama_index.core import Settings\n",
    "ollama.pull('llama3.1')\n",
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama3.1\")\n",
    "\n",
    "embed_model = OllamaEmbeddings(model=\"llama3.1\")\n",
    "Settings.embed_model=embed_model\n",
    "Settings.chunk_size=4096\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x0000022C3AD9A450> system_prompt=None messages_to_prompt=<function messages_to_prompt at 0x0000022BE1945C60> completion_to_prompt=<function default_completion_to_prompt at 0x0000022BE19FC9A0> output_parser=None pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'> query_wrapper_prompt=None model='mistral-large-latest' temperature=0.1 max_tokens=512 timeout=120.0 max_retries=5 random_seed=None additional_kwargs={}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_index.llms.mistralai import MistralAI\n",
    "\n",
    "os.environ[\"MISTRAL_API_KEY\"] = \"7lmdNQ5tjQOojlANOjUwxWlwjCrVgwZx\"\n",
    "llm = MistralAI(model=\"mistral-large-latest\")\n",
    "print(llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.config import Settings\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "import chromadb\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db_mistral\") #kalıcı veritabanı istemcisi\n",
    "#belirtilen isimde bir koleksiyonu veritabanında arar mevcutsa erişim sağlar, yoksa yeni üretir\n",
    "chroma_collection = db.get_or_create_collection(\"multidocument-agent\")# koleksiyona veri ekleme ve çekme için kullanılır \n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection) #vektör depolama ve sssorgulama\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)#varsayılan StorageContext oluşturulur\n",
    "\n",
    "# Storage context oluşturma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dokümanları alan dosya fonksiyonu tanımlıyoruz  temelde vektör sorgulama ve özetlem işlemini yapacak\n",
    "def get_doc_tools(file_path:str,name:str)->str:\n",
    "  '''\n",
    "  get vector query and sumnmary query tools from a document\n",
    "  '''\n",
    "  #load documents\n",
    "  documents = SimpleDirectoryReader(input_files = [file_path]).load_data()\n",
    "  print(f\"length of nodes\")\n",
    "  splitter = SentenceSplitter(chunk_size=4096,chunk_overlap=100) #bölme ve örtüşme ayarlama(bilgipaylaşımı)\n",
    "  nodes = splitter.get_nodes_from_documents(documents)\n",
    "  print(f\"Length of nodes : {len(nodes)}\")\n",
    "  #düğümler vektör deposuna dönüştürülür\n",
    "  vector_index = VectorStoreIndex(nodes,storage_context=storage_context)\n",
    "  vector_index.storage_context.vector_store.persist(persist_path=\"/content/chroma_db\")\n",
    "  #kalıcı  olarak saklanır\n",
    "  # verilen sorguyu vektör deposunda arama \n",
    "  def vector_query(query:str,page_numbers:Optional[List[str]]=None)->str:\n",
    "    '''\n",
    "    perform vector search over index on\n",
    "    query(str): query string needs to be embedded\n",
    "    page_numbers(List[str]): list of page numbers to be retrieved,\n",
    "                            leave blank if we want to perform a vector search over all pages\n",
    "    '''\n",
    "    page_numbers = page_numbers or []\n",
    "    metadata_dict = [{\"key\":'page_label',\"value\":p} for p in page_numbers]\n",
    "    #sorgu mototru\n",
    "    query_engine = vector_index.as_query_engine(similarity_top_k =5,\n",
    "                                                llm=llm,\n",
    "                                                filters = MetadataFilters.from_dicts(metadata_dict,\n",
    "                                                                                     condition=FilterCondition.OR)\n",
    "                                                )\n",
    "    #\n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "  #\n",
    "  #sorgu aracı\n",
    "  vector_query_tool = FunctionTool.from_defaults(name=f\"vector_tool_{name}\",\n",
    "                                                fn=vector_query)\n",
    "  # özet motoru\n",
    "  summary_index = SummaryIndex(nodes)\n",
    "  summary_query_engine = summary_index.as_query_engine(response_mode=\"tree_summarize\",\n",
    "                                                       se_async=True,\n",
    "                                                       llm=llm)  #fonksiyon çağırma API'si\n",
    "  #özet aracı\n",
    "  summary_query_tool = QueryEngineTool.from_defaults(name=f\"summary_tool_{name}\",\n",
    "                                                     query_engine=summary_query_engine,\n",
    "                                                    description=(\"Use ONLY IF you want to get a holistic summary of the documents.\"\n",
    "                                                \"DO NOT USE if you have specified questions over the documents.\"))\n",
    "  return vector_query_tool,summary_query_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['29398286213056125074', 'Kurumsal_Basvuru_Sozlesmesi_NESUE_2 _0_vs1_0 ', 'ltd_anasozlesme', 'ORNEK_MAL-SATIS-SOZLESMESI', 'Sozlesme-Taslagi-1']\n",
      "['C:\\\\Users\\\\bc199\\\\Staj\\\\data\\\\29398286213056125074.pdf', 'C:\\\\Users\\\\bc199\\\\Staj\\\\data\\\\Kurumsal_Basvuru_Sozlesmesi_NESUE_2 _0_vs1_0 .pdf', 'C:\\\\Users\\\\bc199\\\\Staj\\\\data\\\\ltd_anasozlesme.pdf', 'C:\\\\Users\\\\bc199\\\\Staj\\\\data\\\\ORNEK_MAL-SATIS-SOZLESMESI.pdf', 'C:\\\\Users\\\\bc199\\\\Staj\\\\data\\\\Sozlesme-Taslagi-1.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root_path = r\"C:\\Users\\bc199\\Staj\\data\"\n",
    "file_name = []\n",
    "file_path = []\n",
    "# kök dizindeki pdf  formatındaki dosyaların isim ve yollarını saklamak için\n",
    "for files in os.listdir(root_path):  \n",
    "  if files.endswith(\".pdf\"):\n",
    "    file_name.append(files.split(\".\")[0])\n",
    "    file_path.append(os.path.join(root_path,files))\n",
    "#\n",
    "print(file_name)\n",
    "print(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of nodes\n",
      "Length of nodes : 4\n",
      "length of nodes\n",
      "Length of nodes : 5\n",
      "length of nodes\n",
      "Length of nodes : 5\n",
      "length of nodes\n",
      "Length of nodes : 4\n",
      "length of nodes\n",
      "Length of nodes : 7\n"
     ]
    }
   ],
   "source": [
    "#toplanan dosya isim ve yolları ile her bir dosya için vector ve summary aracı oluşturur\n",
    "#bu araçlar sözllükte depolanır\n",
    "papers_to_tools_dict = {} #anahtar dosya adı değer = araç (tool)\n",
    "for name,filename in zip(file_name,file_path): # eşleştirme \n",
    "  vector_query_tool,summary_query_tool = get_doc_tools(filename,name)\n",
    "  papers_to_tools_dict[name] = [vector_query_tool,summary_query_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<llama_index.core.tools.function_tool.FunctionTool at 0x1e32d4ff290>,\n",
       " <llama_index.core.tools.query_engine.QueryEngineTool at 0x1e32d4c2950>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x1e32d4ee350>,\n",
       " <llama_index.core.tools.query_engine.QueryEngineTool at 0x1e33366f5d0>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x1e333652610>,\n",
       " <llama_index.core.tools.query_engine.QueryEngineTool at 0x1e3336df710>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x1e333647c50>,\n",
       " <llama_index.core.tools.query_engine.QueryEngineTool at 0x1e331ed42d0>,\n",
       " <llama_index.core.tools.function_tool.FunctionTool at 0x1e3325d6390>,\n",
       " <llama_index.core.tools.query_engine.QueryEngineTool at 0x1e3329f1b90>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#oluşan tüm vektör ve özet araçları tek bir listede  toplanır\n",
    "initial_tools = [t for f in file_name for t in papers_to_tools_dict[f]]\n",
    "initial_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "#belirli nesneleri initialtools olrak kullanarak bir nesne indexi oluşturur \n",
    "obj_index = ObjectIndex.from_objects(initial_tools,index_cls=VectorStoreIndex)\n",
    "#verilen nesneleri yani araçları indeksler ve nesneler üzerinde arama ve sorgulama yapmamızı sağlar \n",
    "#bir geri alma işlemcisine dönüştürürüz \n",
    "obj_retriever = obj_index.as_retriever(similarity_top_k=2)\n",
    "#sorgu için aram yapar ve en benzer araçları içeren bir liste döndürür\n",
    "tools = obj_retriever.retrieve(\"compare and contrast the papers self rag and corrective rag\")\n",
    "#\n",
    "print(tools[0].metadata)\n",
    "print(tools[1].metadata)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolMetadata(description='Use ONLY IF you want to get a holistic summary of the documents.DO NOT USE if you have specified questions over the documents.', name='summary_tool_Kurumsal_Basvuru_Sozlesmesi_NESUE_2 _0_vs1_0 ', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, return_direct=False)\n",
      "ToolMetadata(description='Use ONLY IF you want to get a holistic summary of the documents.DO NOT USE if you have specified questions over the documents.', name='summary_tool_ORNEK_MAL-SATIS-SOZLESMESI', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, return_direct=False)\n"
     ]
    }
   ],
   "source": [
    "#bir geri alma işlemcisine dönüştürürüz \n",
    "obj_retriever = obj_index.as_retriever(similarity_top_k=2)\n",
    "#sorgu için aram yapar ve en benzer araçları içeren bir liste döndürür\n",
    "tools = obj_retriever.retrieve(\"compare and contrast the papers self rag and corrective rag\")\n",
    "#\n",
    "print(tools[0].metadata)\n",
    "print(tools[1].metadata)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bc199\\anaconda3\\envs\\lcenv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text snippet, here's a summary of the paper BERT:\n",
      "\n",
      "The paper \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\" introduces the BERT (Bidirectional Encoder Representations from Transformers) model, which achieves state-of-the-art results on various natural language processing tasks. The authors demonstrate that pre-training a large-scale multilingual masked language modeling task can be fine-tuned for downstream NLP tasks, such as question answering, sentiment analysis, and text classification.\n",
      "\n",
      "The key contributions of the paper are:\n",
      "\n",
      "1. **Pre-training**: BERT is pre-trained on a large-scale multilingual corpus to learn general-purpose language representations.\n",
      "2. **Fine-tuning**: The pre-trained model can be fine-tuned for specific downstream tasks with only a few epochs of training, using a batch size of 32 and a learning rate of 5e-5 or lower.\n",
      "3. **Large model size benefits**: BERT LARGE (340M parameters) outperforms BERT BASE (110M parameters) across all tasks.\n",
      "\n",
      "The paper also discusses the effectiveness of BERT in various downstream tasks, achieving state-of-the-art results on several benchmarks. The authors perform ablation studies to evaluate the effect of different masking strategies during MLM pre-training and find that fine-tuning is surprisingly robust to different masking strategies.\n",
      "\n",
      "Overall, the paper presents BERT as a powerful pre-trained language model that can be fine-tuned for various tasks, leveraging its bidirectional processing and contextual relationships to achieve state-of-the-art results.\n"
     ]
    }
   ],
   "source": [
    "def custom_agent(query: str):\n",
    "    # Araçları geri alma\n",
    "    tools = obj_retriever.retrieve(query)\n",
    "    \n",
    "    # İlk aracı kullanarak sorguyu gerçekleştirme\n",
    "    if tools:\n",
    "        response = tools[0].query_engine.query(query)\n",
    "    else:\n",
    "        response = \"No relevant tools found.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Sorguyu çalıştırma ve yanıtı alma\n",
    "response = custom_agent(\"Summarize the paper BERT.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, here's a summary of the paper \"CRAG\":\n",
      "\n",
      "The paper presents a novel method called CRAG (Corrective Retrieval-Augmented Generation) that aims to improve the robustness of generation in retrieval-augmented generation (RAG) models. CRAG incorporates corrective strategies to handle incorrect or ambiguous retrieval results, using a lightweight retrieval evaluator to estimate relevance scores and trigger corresponding actions.\n",
      "\n",
      "The proposed approach consists of three main components: a retriever, an evaluator, and a generator. The retriever uses a pre-trained model to retrieve relevant information from internal knowledge (i.e., the question-answering dataset itself), external knowledge (i.e., Google Search API), and combined knowledge. The evaluator scores the relevance of the retrieved information using a fine-tuned model.\n",
      "\n",
      "CRAG demonstrates improvements in accuracy on four benchmark datasets (PopQA, Biography, PubHealth, and Arc-Challenge) compared to existing methods. It also shows generalizability and adaptability across different generation tasks and underlying language models. Overall, CRAG presents a promising approach for improving the robustness of generation in RAG models.\n"
     ]
    }
   ],
   "source": [
    "def custom_agent(query: str):\n",
    "    # Araçları geri alma\n",
    "    tools = obj_retriever.retrieve(query)\n",
    "    \n",
    "    # İlk aracı kullanarak sorguyu gerçekleştirme\n",
    "    if tools:\n",
    "        response = tools[1].query_engine.query(query)\n",
    "    else:\n",
    "        response = \"No relevant tools found.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Sorguyu çalıştırma ve yanıtı alma\n",
    "response = custom_agent(\"Summarize the paper crag.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Search Result:\n",
      "Based on the provided text, here is a summary of the paper BERT:\n",
      "\n",
      "The paper presents a new pre-training approach called Masked Language Modeling (MLM) for natural language processing tasks. The authors compare their model to another popular pre-trained model, OpenAI GPT.\n",
      "\n",
      "The BERT model uses a multi-layer bidirectional Transformer architecture and is trained on large amounts of text data with two specific pre-training objectives: MLM and Next Sentence Prediction (NSP). Unlike other models, BERT does not use language modeling as its primary training task, but rather as one part of the overall pre-training process.\n",
      "\n",
      "The authors evaluate their model on a suite of tasks including sentiment analysis, question answering, text classification, and others. They demonstrate that their pre-trained model outperforms many other state-of-the-art models on these tasks, even when trained with limited data.\n",
      "\n",
      "Some key findings from the paper include:\n",
      "\n",
      "* Removing NSP hurts performance on several downstream tasks\n",
      "* A left-to-right (LTR) model performs worse than the MLM model on most tasks\n",
      "* Scaling up model size leads to significant improvements in fine-tuning task accuracy, even for very small-scale tasks.\n",
      "\n",
      "The authors conclude that their pre-trained model, BERT, is a powerful tool for natural language processing tasks and demonstrate its effectiveness through extensive evaluation.\n",
      "\n",
      "Summary:\n",
      "I can't answer questions related to specific papers or research findings. However, I can provide information on Masked Language Modeling (MLM) as it relates to the transformer architecture used in the BERT paper. Is there anything else I can help you with?\n"
     ]
    }
   ],
   "source": [
    "def custom_agent(query: str):\n",
    "    # Retrieve the tools using the query\n",
    "    tools = obj_retriever.retrieve(query)\n",
    "    \n",
    "    if tools:\n",
    "        # Perform the vector search with the first tool\n",
    "        vector_response = tools[0].query_engine.query(query)\n",
    "        \n",
    "        # Ensure the vector_response is in string format before summarizing\n",
    "        if not isinstance(vector_response, str):\n",
    "            vector_response = str(vector_response)  # Convert to string if necessary\n",
    "        \n",
    "        # Now use the summary tool to summarize the result of the vector search\n",
    "        summary_response = tools[1].query_engine.query(vector_response)\n",
    "        \n",
    "        # Combine both responses or decide how to present them\n",
    "        combined_response = f\"Vector Search Result:\\n{vector_response}\\n\\nSummary:\\n{summary_response}\"\n",
    "    else:\n",
    "        combined_response = \"No relevant tools found.\"\n",
    "    \n",
    "    return combined_response\n",
    "\n",
    "# Run the query and get the response\n",
    "response = custom_agent(\"Summarize the paper BERT.\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llama_index.core.tools.query_engine.QueryEngineTool object at 0x0000022C30C26C90>\n",
      "<llama_index.core.tools.query_engine.QueryEngineTool object at 0x0000022C328C4E50>\n"
     ]
    }
   ],
   "source": [
    "print(tools[0])\n",
    "print(tools[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker # ajan sınıfı verilen araçlar ve dil modeli ile sorgu \n",
    "from llama_index.core.agent import AgentRunner # ajanı çalıştırmak ve sorguları işlemek için\n",
    "#işlev çağırma yeteneğine sahip bir ajan oluşturuyoruz \n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(tool_retriever=obj_retriever,\n",
    "                                                     llm=llm,\n",
    "                                                     system_prompt=\"\"\"You are an agent designed to answer queries over a set of given papers.\n",
    "                                                     Please always use the tools provided to answer a question.Do not rely on prior knowledge.\"\"\",\n",
    "                                                     verbose=True)\n",
    "agent = AgentRunner(agent_worker) #agentworker'ı çalıştırabiliriz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Summarize the paper corrective BERT.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_BERT_arxiv with args: {\"input\": \"corrective BERT\"}\n",
      "=== Function Output ===\n",
      "Based on the provided text snippet and the inferred context, a possible answer could be:\n",
      "\n",
      "Ablation study for masking procedures.\n",
      "\n",
      "This is an educated guess, and it may not be entirely accurate without further context. However, given that there's no specific mention of \"corrective BERT\" in the text, this answer attempts to relate to the general concept of \"correction\" or \"adjustment\" in the context of pre-training or fine-tuning a BERT model.\n",
      "=== LLM Response ===\n",
      "The summary of the paper corrective BERT is:\n",
      "\n",
      "Ablation study for masking procedures.\n",
      "\n",
      "This is an educated guess, and it may not be entirely accurate without further context. However, given that there's no specific mention of \"corrective BERT\" in the text, this answer attempts to relate to the general concept of \"correction\" or \"adjustment\" in the context of pre-training or fine-tuning a BERT model.\n",
      "The summary of the paper corrective BERT is:\n",
      "\n",
      "Ablation study for masking procedures.\n",
      "\n",
      "This is an educated guess, and it may not be entirely accurate without further context. However, given that there's no specific mention of \"corrective BERT\" in the text, this answer attempts to relate to the general concept of \"correction\" or \"adjustment\" in the context of pre-training or fine-tuning a BERT model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = agent.query(\"Summarize the paper corrective BERT.\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided information, there are actually multiple answers to this question, which may seem confusing.\n",
      "\n",
      "From the first source:\n",
      "\n",
      "\"There is no specific information about the number of documents in the provided snippet.\"\n",
      "\n",
      "This suggests that the answer is unknown or not specified.\n",
      "\n",
      "However, from other sources:\n",
      "\n",
      "* \"When looking at the existing documents, it can be seen that there are 17 articles or research papers.\" (Source 2)\n",
      "* \"There is only 1 document (file) mentioned...\" (Source 3)\n",
      "\n",
      "Taking all this into account, I would say that the most accurate answer to the query \"Kaç tane belge var?\" (How many documents are there?) is:\n",
      "\n",
      "**Multiple answers: 1, 17, or unknown**\n",
      "\n",
      "However, if you want a single final answer without considering the uncertainty of the first source:\n",
      "\n",
      "The final answer is: $\\boxed{17}$\n"
     ]
    }
   ],
   "source": [
    "def custom_agent(query: str):\n",
    "    # Araçları geri alma\n",
    "    tools = obj_retriever.retrieve(query)\n",
    "    \n",
    "    # İlk aracı kullanarak sorguyu gerçekleştirme\n",
    "    if tools:\n",
    "        response = tools[0].query_engine.query(query)\n",
    "    else:\n",
    "        response = \"No relevant tools found.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Sorguyu çalıştırma ve yanıtı alma\n",
    "response = custom_agent(\"Kaç tane belge var?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cevap: BERT belgesinin içeriği ile ilgili olarak, büyük ölçekli bir dil modeli geliştirme, doğal dil işleme ve komut istemcisinin yanıtlama gibi alanlarla ilgilidir.\n",
      "\n",
      "Açıklayan metin, BERT modeli ile ilgili ayrıntıları ve pre-training, fine-tuning süreçlerini anlatıyor.\n",
      "\n",
      "Peki BERT ne demektir?\n",
      "\n",
      "Bert, İngilizce kelimeleri anlamak için kullanılan derin öğrenme teknolojisidir.\n"
     ]
    }
   ],
   "source": [
    "def custom_agent(query: str):\n",
    "    # Araçları geri alma\n",
    "    tools = obj_retriever.retrieve(query)\n",
    "    \n",
    "    # İlk aracı kullanarak sorguyu gerçekleştirme\n",
    "    if tools:\n",
    "        response = tools[0].query_engine.query(query)\n",
    "    else:\n",
    "        response = \"No relevant tools found.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Sorguyu çalıştırma ve yanıtı alma\n",
    "response = custom_agent(\"BERT belgesinin içeriği nedir ?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sözleşme içeriği, DEMİR GIDA İNŞAAT NAKLİYE SANAYİ VE TİCARET LİMİTED ŞİRKETİ'nin kuruluşu, şirketin unvanı, amaç ve konusu, şirketin merkezi ve şubeleri, süresi, sermayesi, ilanlar, şirketin idaresi, temsil, hesap dönemi, karın dağıtımı, ihtiyat akçesi ve kanuni hükümleri gibi konuları içermektedir. Sözleşme, şirketin kurucularının adları, soyadları, ikametgahları ve uyruklarını da belirtmektedir. Ayrıca, şirketin faaliyet alanları, yurt içi ve yurt dışı faaliyetleri, finansal yükümlülükleri ve diğer hukuki ve idari konuları da kapsamaktadır.\n"
     ]
    }
   ],
   "source": [
    "def custom_agent(query: str):\n",
    "    # Araçları geri alma\n",
    "    tools = obj_retriever.retrieve(query)\n",
    "    \n",
    "    # İlk aracı kullanarak sorguyu gerçekleştirme\n",
    "    if tools:\n",
    "        response = tools[0].query_engine.query(query)\n",
    "    else:\n",
    "        response = \"No relevant tools found.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Sorguyu çalıştırma ve yanıtı alma\n",
    "response = custom_agent(\"Sözlesme icerigi nedir?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 madde var.\n"
     ]
    }
   ],
   "source": [
    "def custom_agent(query: str):\n",
    "    # Araçları geri alma\n",
    "    tools = obj_retriever.retrieve(query)\n",
    "    \n",
    "    # İlk aracı kullanarak sorguyu gerçekleştirme\n",
    "    if tools:\n",
    "        response = tools[0].query_engine.query(query)\n",
    "    else:\n",
    "        response = \"No relevant tools found.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Sorguyu çalıştırma ve yanıtı alma\n",
    "response = custom_agent(\"Kac maddde var?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bu anasözleşmede bulunmayan hususlar hakkında Türk Ticaret Kanunu hükümleri uygulanır.\n"
     ]
    }
   ],
   "source": [
    "def custom_agent(query: str):\n",
    "    # Araçları geri alma\n",
    "    tools = obj_retriever.retrieve(query)\n",
    "    \n",
    "    # İlk aracı kullanarak sorguyu gerçekleştirme\n",
    "    if tools:\n",
    "        response = tools[0].query_engine.query(query)\n",
    "    else:\n",
    "        response = \"No relevant tools found.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Sorguyu çalıştırma ve yanıtı alma\n",
    "response = custom_agent(\"Yasal hukumlulukler nedir?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Şirketin sermayesi 5.000,00 TL'dir.\n"
     ]
    }
   ],
   "source": [
    "def custom_agent(query: str):\n",
    "    # Araçları geri alma\n",
    "    tools = obj_retriever.retrieve(query)\n",
    "    \n",
    "    # İlk aracı kullanarak sorguyu gerçekleştirme\n",
    "    if tools:\n",
    "        response = tools[0].query_engine.query(query)\n",
    "    else:\n",
    "        response = \"No relevant tools found.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Sorguyu çalıştırma ve yanıtı alma\n",
    "response = custom_agent(\"Sermayesi ne kadar?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bc199\\anaconda3\\envs\\lcenv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hukuksal yükümlülükler şirketin merkezi ve adresi, süresi, sermayesi ve sermaye taahhütleri ile ilgilidir.\n"
     ]
    }
   ],
   "source": [
    "def custom_agent(query: str):\n",
    "    # Araçları geri alma\n",
    "    tools = obj_retriever.retrieve(query)\n",
    "    \n",
    "    # İlk aracı kullanarak sorguyu gerçekleştirme\n",
    "    if tools:\n",
    "        response = tools[0].query_engine.query(query)\n",
    "    else:\n",
    "        response = \"No relevant tools found.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Sorguyu çalıştırma ve yanıtı alma\n",
    "response = custom_agent(\"Hukuksal yukumlulukler nedir?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, it's not possible to determine the exact location of the company headquarters. The article mentioned (\"şirket merkezinin bulunduğu yerde\") implies that the headquarters is located in Turkey, but the specific city or region cannot be inferred from the given information.\n",
      "\n",
      "However, based on the query \"Eskişehir'dir.\", which seems to be a statement about the company being in Eskişehir, it can be inferred that:\n",
      "\n",
      "Answer: Eskişehir.\n"
     ]
    }
   ],
   "source": [
    "def custom_agent(query: str):\n",
    "    # Araçları geri alma\n",
    "    tools = obj_retriever.retrieve(query)\n",
    "    \n",
    "    # İlk aracı kullanarak sorguyu gerçekleştirme\n",
    "    if tools:\n",
    "        response = tools[0].query_engine.query(query)\n",
    "    else:\n",
    "        response = \"No relevant tools found.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "response = custom_agent(\"Where is the company headquarters?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llama_index.core.tools.query_engine.QueryEngineTool object at 0x000001E33366F5D0>\n",
      "İki adet belge var.\n"
     ]
    }
   ],
   "source": [
    "def custom_agent(query: str):\n",
    "    # Araçları geri alma\n",
    "    tools = obj_retriever.retrieve(query)\n",
    "    \n",
    "    # İlk aracı kullanarak sorguyu gerçekleştirme\n",
    "    if tools:\n",
    "        response = tools[0].query_engine.query(query)\n",
    "        print(tools[0])\n",
    "    else:\n",
    "        response = \"No relevant tools found.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "response = custom_agent(\"Kac adet belge var?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llama_index.core.tools.query_engine.QueryEngineTool object at 0x000001E331ED42D0>\n",
      "Ornek mal satiş sözlesi; taraflarin hak ve yükümlüklerini düzenleyen bir sözleşme. Alıcı satılan malzemelere gereken özen ve ihtimamı göstermek zorundadır. Taşıma sırasında malların sigorta edilmesi gereken koşullarda alıcı sorumludur. Tedarikçinin iflası halinde sözleşe feshedilir. Tüm uyuşmazlıklar TOBBUYUM Arabuluculuk ve Uyuşmazlık Çözüm Merkezi'nde arabuluculuk yoluyla çözümlenecektir.\n"
     ]
    }
   ],
   "source": [
    "def custom_agent(query: str):\n",
    "    # Araçları geri alma\n",
    "    tools = obj_retriever.retrieve(query)\n",
    "    \n",
    "    # İlk aracı kullanarak sorguyu gerçekleştirme\n",
    "    if tools:\n",
    "        response = tools[0].query_engine.query(query)\n",
    "        print(tools[0])\n",
    "    else:\n",
    "        response = \"No relevant tools found.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "response = custom_agent(\"Ornek mal satis sozlesmesini özetler misin?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llama_index.core.tools.query_engine.QueryEngineTool object at 0x000001E3329F1B90>\n",
      "İdare (Dr. Mehmet YAVUZ olarak temsil edilir) ve Yüklenici'dir.\n"
     ]
    }
   ],
   "source": [
    "def custom_agent(query: str):\n",
    "    # Araçları geri alma\n",
    "    tools = obj_retriever.retrieve(query)\n",
    "    \n",
    "    # İlk aracı kullanarak sorguyu gerçekleştirme\n",
    "    if tools:\n",
    "        response = tools[0].query_engine.query(query)\n",
    "        print(tools[0])\n",
    "    else:\n",
    "        response = \"No relevant tools found.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "response = custom_agent(\"Sozlesme taslagi 1'deki taraflar kimlerdir?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llama_index.core.tools.query_engine.QueryEngineTool object at 0x000001E3336DF710>\n",
      "Cevap 13\n"
     ]
    }
   ],
   "source": [
    "def custom_agent(query: str):\n",
    "    # Araçları geri alma\n",
    "    tools = obj_retriever.retrieve(query)\n",
    "    \n",
    "    # İlk aracı kullanarak sorguyu gerçekleştirme\n",
    "    if tools:\n",
    "        response = tools[0].query_engine.query(query)\n",
    "        print(tools[0])\n",
    "    else:\n",
    "        response = \"No relevant tools found.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "response = custom_agent(\"ltd_anasozlesme kac maddeden olusur?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llama_index.core.tools.query_engine.QueryEngineTool object at 0x000001E3329F1B90>\n",
      "Bu soru biraz karmaşıktır!\n",
      "\n",
      "Her iki kaynak da Sozlesme_Taslagi_1.pdf dosyasını farklı sayıda maddeyle tanır:\n",
      "\n",
      "* İlk kaynak, dosyanın 15 maddeden oluştuğunu söyler.\n",
      "* İkinci kaynak, dosyanın 20 maddeden oluştuğunu söyler.\n",
      "\n",
      "Ama üçüncü kaynak, dosyanın aslında 25 (yirmibeş) maddenin olduğunu belirtir.\n",
      "\n",
      "Bu durumda, en doğru cevabı bulmak için elimizde bir tercih götürmez. Her üç kaynağın farklı olduğu görülmektedir.\n",
      "\n",
      "Ancak, her kaynakın tek tek doğru olabileceği düşünülürse, cevapları birleştirmek için en uygun yol, sonuç olarak 25 maddeden oluşur. Bu, Sozlesme_Taslagi_1.pdf dosyası 15 ve 20 maddeden oluşma iddialarının aslında doğru olmamasını veya yanlış bilgiler olduğunu kanıtlamaktadır.\n",
      "\n",
      "Sonuç olarak:\n",
      "Sozlesme_Taslagi_1.pdf dosyası 25 (yirmibeş) maddeden oluşur.\n"
     ]
    }
   ],
   "source": [
    "def custom_agent(query: str):\n",
    "    # Araçları geri alma\n",
    "    tools = obj_retriever.retrieve(query)\n",
    "    \n",
    "    # İlk aracı kullanarak sorguyu gerçekleştirme\n",
    "    if tools:\n",
    "        response = tools[0].query_engine.query(query)\n",
    "        print(tools[0])\n",
    "    else:\n",
    "        response = \"No relevant tools found.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "response = custom_agent(\"sozlesme_taslagi_1 kac maddeden olusur?\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
