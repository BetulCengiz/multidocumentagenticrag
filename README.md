# multidocument agentic rag with ollama

## Project Description
This project uses various tools and libraries for document processing, vector storage, and querying to perform tasks such as document summarization, vector-based search, and natural language understanding. The project integrates models like `Ollama`, `MistralAI`, and `BERT` to process and retrieve information from large sets of documents.

## Setup
### Prerequisites
You will need the following libraries installed to run the code:
- `os`
- `numpy`
- `faiss`
- `nest_asyncio`
- `llama_index`
- `chromadb`
- `einops`
- `accelerate`
- `sentence-transformers`
- `langchain_community`

To install the libraries, run:
```bash
pip install numpy faiss-gpu nest_asyncio llama_index chromadb einops accelerate sentence-transformers langchain_community
